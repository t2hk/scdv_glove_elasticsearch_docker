{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データをクローリングする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p html excel csv json tokenized vector log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事故事例(Excel系)と、事例・状況・原因・対策（HTML系）の2種類を取得する。\n",
    "! ./get_doc.sh > ./log/get_doc.log 2>&1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 取得したデータをCSVまたはJSONに変換する。\n",
    "* 事故事例のExcelをCSVに変換する。\n",
    "* 事例・状況・原因・対策のHTMLはJSONに変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel to CSV\n",
    "!python excel_to_csv.py ./excel/ ./csv/ > ./log/excel_to_csv.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML to JSON\n",
    "# !python html_to_json.py ./html/ ./json/ > ./log/html_to_json.log 2>&1 \n",
    "!python html_to_csv.py ./html/ ./csv/anzen_all.csv > ./log/html_to_csv.log 2>&1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ElasticsearchにIndexを登録する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"anzen\"}"
     ]
    }
   ],
   "source": [
    "# 事例・状況・原因・対策用のインデックスを登録\n",
    "#! curl -XPUT -H \"Content-Type: application/json\" elasticsearch:9200/anzen -d @es_anzen_schema.txt\n",
    "! curl -XPUT -H \"Content-Type: application/json\" elasticsearch:9200/anzen -d @es_anzen_csv_schema.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事例用のインデックスを登録\n",
    "! curl -XPUT -H \"Content-Type: application/json\" elasticsearch:9200/accident -d @es_accident_schema.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Elasticsearchにデータをロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事例・状況・原因・対策データをロード(anzenインデックス)\n",
    "#! ./load_anzen_bulk_es.sh > ./log/load_anzen_bulk_es.log 2>&1\n",
    "! python load_anzen_es.py --host elasticsearch --index anzen --input_csv ./csv/anzen_all.csv  > ./log/load_anzen_es.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事例用データをロード(accidentインデックス)\n",
    "!python load_accident_es.py --host elasticsearch --index accident --input_dir ./csv/  > ./log/load_accident_es.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Elasticsearchでトークナイズし、結果をCSV形式とテキスト形式で保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事例・状況・原因・対策データの文章をトークナイズし、CSVとTXTファイルとして保存する\n",
    "!python es_anzen_tokenize.py --host elasticsearch --index anzen --output tokenized/anzen_tokenized > ./log/es_anzen_tokenize.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事例用データの文章をトークナイズし、CSVとTXTファイルとして保存する\n",
    "!python es_accident_tokenize.py --host elasticsearch --index accident --output tokenized/accident_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GloVeで単語を学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVeを取得する。最初に1回だけ実行すれば良い。\n",
    "! git clone https://github.com/stanfordnlp/GloVe.git\n",
    "! cd GloVe && make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイズしたanzenとaccidentのテキストファイルを結合する。\n",
    "! cat tokenized/anzen_tokenized.txt tokenized/accident_tokenized.txt > tokenized/all_tokens.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVeで学習する。\n",
    "! ./glove.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCDVで文章をベクトル化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anzenとaccidentのCSVをマージする。ベクトル化に必要な列のみ選別し、列名を統一する。\n",
    "!python merge_csv.py --input_anzen tokenized/anzen_tokenized.csv --input_accident tokenized/accident_tokenized.csv --output_csv tokenized/merge_tokenized.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Done...\n",
      "Cluster Assignments Saved...\n",
      "Probabilities of Cluster Assignments saved...\n",
      "100%|███████████████████████████████████| 53033/53033 [00:08<00:00, 5982.13it/s]\n",
      "100%|████████████████████████████████████| 5893/5893 [00:00<00:00, 18155.08it/s]\n",
      "train size:53033  vector size:1000\n",
      "test size:5893  vector size:1000\n",
      "Test start...\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cause   0.565625  0.413242  0.477573       438\n",
      "    measures   0.695560  0.658000  0.676259       500\n",
      "   situation   0.660000  0.474333  0.551971       487\n",
      "       title   0.351852  0.218391  0.269504        87\n",
      "      その他の事業   0.488636  0.176230  0.259036       244\n",
      "      保健・衛生業   0.000000  0.000000  0.000000         3\n",
      "        保健衛生   0.000000  0.000000  0.000000         1\n",
      "       保健衛生業   0.014286  0.043478  0.021505        23\n",
      "          商業   0.511029  0.344913  0.411852       403\n",
      "         官公署   0.033333  0.500000  0.062500         2\n",
      "         建設業   0.657814  0.782979  0.714960      1645\n",
      "       接客娯楽業   0.280000  0.102941  0.150538        68\n",
      "      教育・研究業   0.000000  0.000000  0.000000         4\n",
      "       教育研究業   0.033333  0.133333  0.053333        15\n",
      "      映画・演劇業   0.000000  0.000000  0.000000         4\n",
      "      清掃・と畜業   0.492063  0.208054  0.292453       149\n",
      "      畜産・水産業   0.355263  0.465517  0.402985        58\n",
      "         製造業   0.542781  0.522523  0.532459       777\n",
      "       貨物取扱業   0.342105  0.220339  0.268041        59\n",
      "         農林業   0.689266  0.632124  0.659459       193\n",
      "         通信業   0.032967  0.176471  0.055556        17\n",
      "       運輸交通業   0.581792  0.650238  0.614114       629\n",
      "      金融・広告業   0.052632  0.093750  0.067416        32\n",
      "          鉱業   0.250000  0.327273  0.283465        55\n",
      "\n",
      "    accuracy                       0.555405      5893\n",
      "   macro avg   0.317931  0.297672  0.284374      5893\n",
      "weighted avg   0.581297  0.555405  0.557482      5893\n",
      "\n",
      "Accuracy:  0.5554047174613949\n",
      "Time taken: 138.51839923858643 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python scdv.py --csv_file ./tokenized/merge_tokenized.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全データについてSCDVベクトルを算出し、Elasticsearchに登録する\n",
    "!python scdv_to_es.py --host elasticsearch --input_csv ./tokenized/merge_tokenized.csv > ./log/scdv_to_es.log 2>&1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
